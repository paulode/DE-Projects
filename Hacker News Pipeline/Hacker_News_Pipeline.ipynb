{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODOs:\n",
    "\n",
    "- Rewrite the Pipeline class' output to save a file of the output for each task. This will allow you to \"checkpoint\" tasks so they don't have to be run twice.\n",
    "- Use the nltk package for more advanced natural language processing tasks.\n",
    "- Convert to a CSV before filtering, so you can keep all the stories from 2014 in a raw file.\n",
    "- Fetch the data from Hacker News directly from a JSON API. Instead of reading from the file we gave, you can perform additional data processing using newer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 185), ('google', 167), ('bitcoin', 101), ('open', 92), ('programming', 90), ('web', 89), ('data', 85), ('video', 79), ('python', 76), ('code', 72), ('released', 71), ('using', 71), ('facebook', 71), ('2013', 65), ('javascript', 65), ('source', 64), ('free', 64), ('internet', 63), ('game', 63), ('microsoft', 59), ('c', 59), ('linux', 58), ('app', 57), ('pdf', 55), ('language', 54), ('dont', 54), ('work', 54), ('2014', 52), ('software', 52), ('startup', 51), ('make', 50), ('apple', 50), ('use', 50), ('yc', 48), ('security', 48), ('time', 48), ('github', 45), ('nsa', 45), ('windows', 44), ('way', 41), ('1', 41), ('world', 41), ('like', 41), ('project', 40), ('computer', 40), ('heartbleed', 40), ('users', 37), ('design', 37), ('ios', 37), ('git', 37), ('ceo', 36), ('developer', 36), ('life', 36), ('os', 36), ('vs', 36), ('twitter', 36), ('big', 35), ('day', 35), ('android', 34), ('online', 34), ('court', 33), ('simple', 33), ('years', 33), ('browser', 32), ('mt', 32), ('api', 32), ('learning', 32), ('apps', 32), ('says', 32), ('guide', 32), ('engine', 31), ('gox', 31), ('amazon', 31), ('fast', 31), ('firefox', 31), ('server', 31), ('site', 31), ('problem', 31), ('mozilla', 31), ('year', 30), ('introducing', 30), ('support', 29), ('people', 29), ('million', 29), ('stop', 29), ('text', 29), ('better', 29), ('built', 29), ('development', 28), ('3', 28), ('does', 28), ('tech', 28), ('website', 27), ('chrome', 27), ('library', 27), ('2048', 27), ('developers', 27), ('best', 27), ('just', 27), ('money', 27)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pipeline import Pipeline, build_csv\n",
    "from datetime import datetime\n",
    "import io\n",
    "import csv\n",
    "import string\n",
    "from stop_words import stop_words\n",
    "import operator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "@pipeline.task()\n",
    "def file_to_json():\n",
    "    \n",
    "    f = open('hn_stories_2014.json', 'r')\n",
    "    \n",
    "    # Load json file into a Python dictionary\n",
    "    data = json.load(f) # file to string\n",
    "    stories = data['stories'] \n",
    "    \n",
    "    return stories\n",
    "\n",
    "@pipeline.task(depends_on = file_to_json)\n",
    "def filter_stories(stories):\n",
    "    # Return a generator function to avoid memory overflow\n",
    "    def is_popular(story):\n",
    "        return story['points'] > 50 and story['num_comments'] > 1 and not story['title'].startswith('Ask HN')     \n",
    "    return (\n",
    "        story for story in stories\n",
    "        if is_popular(story)\n",
    "    )  \n",
    "\n",
    "@pipeline.task(depends_on = filter_stories)\n",
    "def json_to_csv(stories):\n",
    "\n",
    "    lines = []\n",
    "    for story in stories:\n",
    "        objectID = story['objectID']\n",
    "        created_at = datetime.strptime(story['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        url = story['url']\n",
    "        points = story['points']\n",
    "        title = story['title']\n",
    "        \n",
    "        lines.append((objectID, created_at, url, points, title))\n",
    "    \n",
    "    header = ['objectID', 'created_at', 'url', 'points', 'title']\n",
    "    \n",
    "    return build_csv(lines, header, file=io.StringIO())\n",
    "\n",
    "@pipeline.task(depends_on = json_to_csv)\n",
    "def extract_titles(csv_file):\n",
    "    def inner():\n",
    "        #f = open(csv_file, 'r')\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        headers = next(csv_reader)\n",
    "        idx = headers.index('title')\n",
    "        return (\n",
    "            l[idx] for l in csv_reader\n",
    "        )\n",
    "    return inner()\n",
    "\n",
    "\n",
    "@pipeline.task(depends_on = extract_titles)\n",
    "def clean_titles(titles):\n",
    "    \n",
    "    def remove_punctuation_and_lower_title():\n",
    "        \n",
    "        # Need to review maketrans and translate methods\n",
    "        str_to_remove = string.punctuation + '‘' + '’'\n",
    "        remove = str.maketrans({key: None for key in str_to_remove})\n",
    "        return (\n",
    "            t.translate(remove).lower() for t in titles\n",
    "        )\n",
    "    return remove_punctuation_and_lower_title()\n",
    "\n",
    "@pipeline.task(depends_on = clean_titles)\n",
    "def build_keyword_dictionary(clean_titles):\n",
    "    \n",
    "    word_count = {}\n",
    "    \n",
    "    for t in clean_titles:\n",
    "        words = t.split()\n",
    "        for w in words:\n",
    "            if w not in stop_words:\n",
    "                if w not in word_count.keys():\n",
    "                    word_count[w] = 0 \n",
    "                word_count[w] += 1\n",
    "    return word_count\n",
    "\n",
    "@pipeline.task(depends_on = build_keyword_dictionary)\n",
    "def top_100_words_used_in_titles(word_count):\n",
    "    \n",
    "    # sorted(word_count, key=word_count.get, reverse=True)\n",
    "    sorted_words = sorted(word_count.items(), key=operator.itemgetter(1), \n",
    "                          reverse = True)\n",
    "    return sorted_words[:100]\n",
    "    \n",
    "            \n",
    "output = pipeline.run()\n",
    "print(output[top_100_words_used_in_titles])\n",
    "print() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The code below is for test purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('new', 185), ('google', 167), ('bitcoin', 101), ('open', 92), ('programming', 90), ('web', 89), ('data', 85), ('video', 79), ('python', 76), ('code', 72)]\n"
     ]
    }
   ],
   "source": [
    "def file_to_json():\n",
    "    \n",
    "    f = open('hn_stories_2014.json', 'r')\n",
    "    \n",
    "    # Load json file into a Python dictionary\n",
    "    data = json.load(f) # file to string\n",
    "    stories = data['stories'] \n",
    "    \n",
    "    return stories\n",
    "\n",
    "def filter_stories(stories):\n",
    "    # Return a generator function to avoid memory overflow\n",
    "    def is_popular(story):\n",
    "        return story['points'] > 50 and story['num_comments'] > 1 and not story['title'].startswith('Ask HN')     \n",
    "    return (\n",
    "        story for story in stories\n",
    "        if is_popular(story)\n",
    "    )  \n",
    "\n",
    "def json_to_csv(stories):\n",
    "\n",
    "    lines = []\n",
    "    for story in stories:\n",
    "        objectID = story['objectID']\n",
    "        created_at = datetime.strptime(story['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        url = story['url']\n",
    "        points = story['points']\n",
    "        title = story['title']\n",
    "        \n",
    "        lines.append((objectID, created_at, url, points, title))\n",
    "    \n",
    "    header = ['objectID', 'created_at', 'url', 'points', 'title']\n",
    "    \n",
    "    return build_csv(lines, header, file=io.StringIO())\n",
    "\n",
    "def extract_titles(csv_file):\n",
    "    def inner():\n",
    "        #f = open(csv_file, 'r')\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        headers = next(csv_reader)\n",
    "        idx = headers.index('title')\n",
    "        return (\n",
    "            l[idx] for l in csv_reader\n",
    "        )\n",
    "    return inner()\n",
    "\n",
    "def clean_titles(titles):\n",
    "    \n",
    "    def remove_punctuation_and_lower_title():\n",
    "        \n",
    "        # Need to review maketrans and translate methods\n",
    "        str_to_remove = string.punctuation + '‘' + '’'\n",
    "        remove = str.maketrans({key: None for key in str_to_remove})\n",
    "        return (\n",
    "            t.translate(remove).lower() for t in titles\n",
    "        )\n",
    "    return remove_punctuation_and_lower_title()\n",
    "\n",
    "def build_keyword_dictionary(clean_titles):\n",
    "    \n",
    "    word_count = {}\n",
    "    \n",
    "    for t in clean_titles:\n",
    "        words = t.split()\n",
    "        for w in words:\n",
    "            if w not in stop_words:\n",
    "                if w not in word_count.keys():\n",
    "                    word_count[w] = 0 \n",
    "                word_count[w] += 1\n",
    "    return word_count\n",
    "\n",
    "def top_100_words_used_in_titles(word_count):\n",
    "    sorted_words = sorted(word_count.items(), key=operator.itemgetter(1), \n",
    "                          reverse = True)\n",
    "    \n",
    "    print(type(sorted_words))\n",
    "    \n",
    "    return sorted_words[:10]\n",
    "    \n",
    "    \n",
    "    \n",
    "file = file_to_json()\n",
    "stories = filter_stories(file)\n",
    "csv_file = json_to_csv(stories)\n",
    "\n",
    "titles = extract_titles(csv_file)\n",
    "clean_titles = clean_titles(titles)\n",
    "word_count = build_keyword_dictionary(clean_titles)\n",
    "sorted_words = top_100_words_used_in_titles(word_count)\n",
    "\n",
    "print(sorted_words)\n",
    "\n",
    "for t in clean_titles:\n",
    "    print(t)\n",
    "    break\n",
    "\n",
    "# True Goodbye: ‘Using TrueCrypt Is Not Secure’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-05-29 04:27:42\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "created_at = '2014-05-29T04:27:42Z'\n",
    "\n",
    "dt = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'story_id': None, '_highlightResult': {'author': {'matchLevel': 'none', 'matchedWords': [], 'value': 'TuxLyn'}, 'title': {'matchLevel': 'none', 'matchedWords': [], 'value': 'DuckDuckGo Settings'}, 'url': {'matchLevel': 'none', 'matchedWords': [], 'value': 'https://duckduckgo.com/settings'}, 'story_text': {'matchLevel': 'none', 'matchedWords': [], 'value': ''}}, 'title': 'DuckDuckGo Settings', '_tags': ['story', 'author_TuxLyn', 'story_7815290'], 'created_at': '2014-05-29T08:25:40Z', 'story_url': None, 'author': 'TuxLyn', 'created_at_i': 1401351940, 'comment_text': None, 'url': 'https://duckduckgo.com/settings', 'objectID': '7815290', 'story_text': '', 'story_title': None, 'points': 1, 'num_comments': 0, 'parent_id': None}\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print((test['stories'][0]))\n",
    "\n",
    "s = test['stories']\n",
    "\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yep\n"
     ]
    }
   ],
   "source": [
    "#print(stop_words)\n",
    "\n",
    "if 'the' in stop_words:\n",
    "    print('yep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
